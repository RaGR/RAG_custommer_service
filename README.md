# ğŸ’¬ RAG DM Bot â€” FastAPI + SQLite + FAISS + OpenRouter LLM

A retrieval-augmented generation (RAG) micro-service that answers Persian (ÙØ§Ø±Ø³ÛŒ) user queries about beauty & cosmetics products.  
It combines a **local SQLite + FAISS** knowledge base with a **free OpenRouter LLM** (DeepSeek Chat v3.1) for fluent contextual replies.

---

## ğŸ§  Architecture Overview

> Hybrid RAG Stack  
> **FastAPI (backend)** â†’ **SQLite + FTS5 + FAISS retrieval** â†’ **Prompt builder (Farsi)** â†’ **LLM API (OpenRouter)**  

Key components:

- **FastAPI** service with `/simulate_dm` and `/` (web chat UI)
- **SQLite** product database (`products` table) + FTS5 index  
- **FAISS** semantic vector index (`paraphrase-multilingual-MiniLM-L12-v2`)
- **Hybrid retrieval:** vector âˆª keyword merge
- **Prompt policy:** concise, Farsi-only, citation-based
- **LLM Client:** DeepSeek Chat v3.1 via OpenRouter API
- **Debug routes:** `/health`, `/debug/retrieve`, `/debug/prompt`

---

## ğŸ—‚ï¸ Project Structure

```

rag-instabot/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ core/config.py
â”‚   â”œâ”€â”€ retrieval/{fts.py,vector.py,normalize.py}
â”‚   â”œâ”€â”€ prompting/builder.py
â”‚   â”œâ”€â”€ llm/client.py
â”‚   â”œâ”€â”€ routers/{dm.py,debug.py}
â”‚   â””â”€â”€ main.py
â”œâ”€â”€ db/app_data.sqlite
â”œâ”€â”€ data/faiss_index/{index.faiss,meta.npy}
â”œâ”€â”€ scripts/{setup_fts.sh,build_vectors.py,rebuild_db.sh}
â”œâ”€â”€ .env.example
â”œâ”€â”€ README.md
â””â”€â”€ images/
â”œâ”€â”€ proj-structure.png
â”œâ”€â”€ env-structure.png
â”œâ”€â”€ db-snapshot.png
â”œâ”€â”€ cpu_vectors_building.png
â””â”€â”€ chat-tested.png

````

---

## âš™ï¸ Environment & Config

Create and activate a virtual env:

```bash
python3 -m venv .venvs
source .venvs/bin/activate
pip install --upgrade pip
pip install fastapi uvicorn[standard] httpx faiss-cpu sentence-transformers python-dotenv pydantic-settings
````

### `.env.example`

```env
APP_ENV=dev
APP_PORT=8000
RATE_LIMIT_PER_MIN=60
LOG_LEVEL=INFO

# --- Database & Vector ---
DB_PATH=rag-instabot/db/app_data.sqlite
INDEX_PATH=rag-instabot/data/faiss_index
EMBED_MODEL=sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2

# --- LLM Provider (OpenRouter) ---
LLM_PROVIDER=openrouter
LLM_API_BASE=https://openrouter.ai/api/v1
LLM_MODEL=deepseek/deepseek-chat-v3.1:free
LLM_API_KEY=sk-**************

# Optional analytics headers (ASCII only)
OR_HTTP_REFERER=http://localhost:8000/
OR_X_TITLE=RAG-Instabot
```

Copy it to `.env` and insert your **OpenRouter API key**.

---

## ğŸ§© Build & Index the Data

1. **FTS5 setup**

```bash
bash scripts/setup_fts.sh
```

2. **CPU-only vector embedding**

```bash
python scripts/build_vectors.py
```

(Uses Sentence-Transformers MiniLM model; runs entirely on CPU.)

3. Check outputs:

```
data/faiss_index/index.faiss
data/faiss_index/meta.npy
```

---

## ğŸš€ Run the Service

```bash
uvicorn app.main:app --reload --port 8000
```

Visit â†’ [http://127.0.0.1:8000/](http://127.0.0.1:8000/)

---

## ğŸ’» Web Chat UI

Lightweight built-in HTML interface for testing:

- Type a Farsi query (e.g. `Ø´Ø§Ù…Ù¾Ùˆ Ø¨Ø±Ø§ÛŒ Ù…Ùˆ Ø¢Ø³ÛŒØ¨â€ŒØ¯ÛŒØ¯Ù‡`)
- The system performs hybrid retrieval + LLM response.

<p align="center">
  <img src="images/chat-tested.png" width="600"/>
</p>

---

## ğŸ” Debug Endpoints

| Endpoint                | Description                     |
| ----------------------- | ------------------------------- |
| `/health`               | Environment / LLM status        |
| `/debug/retrieve?q=...` | Inspect FAISS + FTS hits        |
| `/debug/prompt?q=...`   | Preview full prompt sent to LLM |

Example:

```bash
curl "http://127.0.0.1:8000/debug/retrieve?q=Ø³Ø±Ù… ÙˆÛŒØªØ§Ù…ÛŒÙ† C Ø¨Ø±Ø§ÛŒ Ù¾ÙˆØ³Øª Ø­Ø³Ø§Ø³"
```

---

## ğŸ§± Development Snapshots

| Stage                         | Preview                                                  |
| :---------------------------- | :------------------------------------------------------- |
| Project structure             | <img src="images/proj-structure.png" width="450"/>       |
| Environment variables         | <img src="images/env-structure.png" width="450"/>        |
| Database (120 rows)           | <img src="images/db-snapshot.png" width="450"/>          |
| CPU vector building           | <img src="images/cpu_vectors_building.png" width="450"/> |
| Chat test (working RAG + LLM) | <img src="images/chat-tested.png" width="450"/>          |

---

## âœ… Features Completed (Commit Stage)

- âœ… SQLite DB (120 Persian product rows)
- âœ… FTS5 search + auto triggers
- âœ… Vector index (FAISS + MiniLM CPU)
- âœ… Hybrid retrieval merge
- âœ… Prompt policy in Farsi
- âœ… OpenRouter LLM integration (DeepSeek v3.1)
- âœ… Browser chat UI + API debug routes
- âœ… Unicode-safe HTTP headers patch

---

## ğŸ§­ Next Roadmap

- ğŸ”¹ Add semantic re-ranking (better result ordering)
- ğŸ”¹ Integrate session memory for multi-turn chat
- ğŸ”¹ Dockerize deployment
- ğŸ”¹ Metrics & tracing for API latency
- ğŸ”¹ Add unit tests and load testing suite

---

## ğŸª„ Quick Demo CLI

```bash
curl -X POST http://127.0.0.1:8000/simulate_dm \
  -H "Content-Type: application/json" \
  -d '{"sender_id":"u1","message_id":"m1","text":"Ú©Ø±Ù… Ø¶Ø¯Ø¢ÙØªØ§Ø¨ Ù…Ù†Ø§Ø³Ø¨ Ù¾ÙˆØ³Øª Ú†Ø±Ø¨"}'
```

Response:

```json
{
  "reply": "Ú©Ø±Ù… Ø¶Ø¯Ø¢ÙØªØ§Ø¨ Ù…Ù†Ø§Ø³Ø¨ Ù¾ÙˆØ³Øª Ú†Ø±Ø¨ Ø§Ø² Ø¨Ø±Ù†Ø¯ Ø§ÙˆØ±Ø¯ÛŒÙ†Ø±ÛŒ ÛŒØ§ Ù„ÙˆØ±Ø¢Ù„ Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ù…ÙˆØ¬ÙˆØ¯ Ø§Ø³Øª. SPF50 Ùˆ Ø¨Ø§ÙØª Ø³Ø¨Ú© Ø¯Ø§Ø±Ø¯."
}
```
